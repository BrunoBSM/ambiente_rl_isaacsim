"""
Script principal para teste e demonstra√ß√£o do ambiente Isaac Sim GO2 Multi-Ambiente.

Este script executa um loop b√°sico de teste do ambiente de reinforcement learning
com m√∫ltiplos rob√¥s GO2, demonstrando o uso da API do Gymnasium com a√ß√µes aleat√≥rias
em paralelo. √â √∫til para verificar se o ambiente multi-rob√¥ est√° funcionando 
corretamente antes de iniciar o treinamento com algoritmos de RL.

Baseado no main.py original, mas adaptado para m√∫ltiplos rob√¥s usando a estrutura
existente do isaac_gym_env.py como fundamenta√ß√£o.

Example:
    Para executar o teste:
    $ ./python.sh main_multi.py
    
Note:
    Este script usa a√ß√µes aleat√≥rias e n√£o treina um agente real.
    Para treinamento com algoritmos de RL, usaremos bibliotecas como
    Stable-Baselines3, Ray RLlib, ou implementa√ß√µes customizadas.
"""

from isaac_gym_multi_env import IsaacSimGo2MultiEnv
import numpy as np
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger("main_multi")


def main():
    """
    Fun√ß√£o principal que executa um loop de teste com a√ß√µes aleat√≥rias para m√∫ltiplos rob√¥s.
    
    Inicializa o ambiente multi-rob√¥, executa passos com a√ß√µes aleat√≥rias,
    monitora recompensas e reseta automaticamente quando epis√≥dios terminam.
    √ötil para debug e verifica√ß√£o b√°sica do funcionamento do ambiente.
    
    Estrutura baseada no main.py original, mas estendida para m√∫ltiplos ambientes.
    """
    # Configura√ß√£o do ambiente multi-rob√¥
    NUM_ENVS = 16  # N√∫mero de rob√¥s (2x2 grid) - reduzido de 16 para 4
    SPACING = 0.5  # spa√ßamento entre rob√¥s em metros
    USE_RELATIVE_CONTROL = False  # Usar controle absoluto inicialmente
    MAX_STEPS = 10000  # N√∫mero m√°ximo de passos - reduzido para teste mais r√°pido

    logger.info("="*60)
    logger.info("INICIANDO TESTE DO AMBIENTE ISAAC SIM GO2 MULTI-ROB√î")
    logger.info("="*60)

    # Inicializa o ambiente multi-rob√¥ (baseado na estrutura do isaac_gym_env.py)
    env = IsaacSimGo2MultiEnv(
        num_envs=NUM_ENVS,
        spacing=SPACING,
        safety_margin=0.1,
        use_relative_control=USE_RELATIVE_CONTROL,
        relative_scale=0.1
    )

    # Primeira observa√ß√£o do ambiente (similar ao main.py original)
    obs, info = env.reset()
    
    # Vari√°veis de controle de epis√≥dio (estendidas para m√∫ltiplos rob√¥s)
    total_rewards = np.zeros(NUM_ENVS)
    episode_counts = np.zeros(NUM_ENVS, dtype=int)
    step_counts = np.zeros(NUM_ENVS, dtype=int)

    logger.info(f"Ambiente inicializado com sucesso!")
    logger.info(f"Dimens√£o das observa√ß√µes: {obs.shape} [{NUM_ENVS} rob√¥s, {obs.shape[1]} obs cada]")
    logger.info(f"Dimens√£o das a√ß√µes: {env.action_space.shape} [{NUM_ENVS} rob√¥s, {env.n_joints} juntas cada]")
    logger.info(f"Controle: {'Relativo' if USE_RELATIVE_CONTROL else 'Absoluto'}")
    logger.info("-" * 60)

    # Loop principal de teste (estrutura baseada no main.py original)
    for step in range(MAX_STEPS):
        # Gera a√ß√µes aleat√≥rias dentro do espa√ßo de a√ß√µes para todos os rob√¥s
        # Formato: [num_envs, n_joints] com valores [-1, 1]
        actions = env.action_space.sample()

        # Executa as a√ß√µes no ambiente (todos os rob√¥s simultaneamente)
        obs, rewards, terminated, truncated, info = env.step(actions)

        # Acumula recompensa total de cada rob√¥
        total_rewards += rewards
        step_counts += 1
        
        # Log b√°sico do progresso (adaptado para m√∫ltiplos rob√¥s)
        if step % 50 == 0:  # Print a cada 50 passos para evitar spam
            logger.info(f"\n=== Passo {step} ===")
            logger.info(f"Recompensas instant√¢neas: {rewards}")
            logger.info(f"Recompensas totais acumuladas: {total_rewards}")
            logger.info(f"Rob√¥s terminados: {np.sum(terminated)}/{NUM_ENVS}")
            logger.info(f"Epis√≥dios por rob√¥: {episode_counts}")

        # Verifica se algum epis√≥dio terminou (baseado no main.py original)
        for env_id in range(NUM_ENVS):
            if terminated[env_id]:
                logger.info(f"\n--- Rob√¥ {env_id} ---")
                logger.info(f"Epis√≥dio {episode_counts[env_id]} finalizado ap√≥s {step_counts[env_id]} passos")
                logger.info(f"Recompensa total: {total_rewards[env_id]:.3f}")
                logger.info(f"Raz√£o da termina√ß√£o: {info['termination_reasons'][env_id]}")
                
                # Reset autom√°tico j√° √© feito pelo environment, apenas atualizamos contadores
                episode_counts[env_id] += 1
                total_rewards[env_id] = 0.0
                step_counts[env_id] = 0
                
                logger.info(f"Iniciando epis√≥dio {episode_counts[env_id]} para rob√¥ {env_id}")
                logger.info("-" * 30)

        # Demonstra√ß√£o de mudan√ßa de modo de controle no meio da simula√ß√£o
        if step == 1000:
            logger.info("\nüîÑ Mudando para controle relativo...")
            env.set_control_mode(use_relative=True, scale=0.05)
            
        if step == 2000:
            logger.info("\nüîÑ Voltando para controle absoluto...")
            env.set_control_mode(use_relative=False)

        # Log detalhado a cada 200 passos
        if step % 200 == 0 and step > 0:
            env.log_environment_states(step, detailed=True)

        # Interrompe se todos os rob√¥s tiveram pelo menos 3 epis√≥dios
        if np.all(episode_counts >= 3):
            logger.info(f"\nüéØ Todos os rob√¥s completaram pelo menos 3 epis√≥dios!")
            logger.info("Finalizando teste...")
            break

    # Estat√≠sticas finais (baseadas no main.py original, mas estendidas)
    logger.info("\n" + "="*60)
    logger.info("ESTAT√çSTICAS FINAIS DO TESTE")
    logger.info("="*60)
    
    for env_id in range(NUM_ENVS):
        logger.info(f"Rob√¥ {env_id}:")
        logger.info(f"  - Epis√≥dios completados: {episode_counts[env_id]}")
        logger.info(f"  - Passos no epis√≥dio atual: {step_counts[env_id]}")
        logger.info(f"  - Recompensa acumulada: {total_rewards[env_id]:.3f}")
    
    logger.info(f"\nTotal de passos executados: {step}")
    logger.info(f"Total de epis√≥dios: {np.sum(episode_counts)}")
    logger.info(f"M√©dia de epis√≥dios por rob√¥: {np.mean(episode_counts):.2f}")

    # Demonstra√ß√£o de a√ß√µes seguras 
    logger.info("\nExecutando demonstra√ß√£o de a√ß√µes seguras...")
    try:
        safe_demo_obs = env.demo_safe_actions(num_steps=100)
        logger.info(f"Demonstra√ß√£o conclu√≠da com {len(safe_demo_obs)} observa√ß√µes coletadas")
    except Exception as e:
        logger.error(f"Erro durante demonstra√ß√£o: {e}")

    # Informa√ß√µes sobre limites das juntas 
    logger.info("\nInforma√ß√µes sobre limites das juntas:")
    try:
        joint_info = env.get_joint_limits_info()
        logger.info(f"Total de rob√¥s: {joint_info['num_envs']}")
        logger.info(f"Juntas por rob√¥: {joint_info['n_joints']}")
        
        # Mostra info detalhada apenas do primeiro rob√¥
        if joint_info['environments']:
            env_0_info = joint_info['environments'][0]
            logger.info(f"Posi√ß√µes atuais rob√¥ 0: {env_0_info['current_positions'][:3]}... (primeiras 3)")
    except Exception as e:
        logger.error(f"Erro ao obter informa√ß√µes das juntas: {e}")

    # Fecha o ambiente e limpa recursos 
    logger.info("\nTeste finalizado. Fechando ambiente...")
    env.close()
    logger.info("Ambiente fechado com sucesso!")


if __name__ == "__main__":
    main()